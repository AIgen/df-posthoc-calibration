{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2fc59-7739-427e-8334-b096a1a4c92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns \n",
    "\n",
    "import assessment \n",
    "import calibration \n",
    "import utils \n",
    "from utils import logit, sigmoid\n",
    "import warnings \n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%autoreload 2\n",
    "\n",
    "mpl.rcParams.update({'font.size': 15})\n",
    "mpl.rcParams.update({\"axes.grid\" : True, \"grid.linestyle\": '--', \n",
    "                     \"grid.alpha\": 0.8, \"grid.color\": \"black\"})\n",
    "mpl.rcParams.update({\"lines.linewidth\" : 3})\n",
    "mpl.style.use('seaborn-colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a6b7f-9c12-445f-825e-bd2d895fd1c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_train = 1000\n",
    "n_val = 500\n",
    "n_test = 4500\n",
    "\n",
    "np.random.seed(0)\n",
    "class true_model:\n",
    "    def predict_proba(x):\n",
    "        prob_1 = 0.1 + 0.8*np.mod(np.floor(x/5), 2)\n",
    "        if(len(prob_1.shape)==1):\n",
    "            return np.vstack((1-prob_1, prob_1)).T\n",
    "        else: \n",
    "            return np.hstack((1-prob_1, prob_1))\n",
    "\n",
    "def create_data(n):    \n",
    "    dat = np.zeros((n, 1))\n",
    "    Y = np.zeros((n))\n",
    "    for i in range(n):\n",
    "        dat[i,:] = 2*np.random.randn((1))\n",
    "        dat[i,:] += (create_data.count/250)\n",
    "        prob = true_model.predict_proba(dat[i,:])[:,1]\n",
    "        Y[i] = int(np.random.random() <= prob)\n",
    "        create_data.count += 1\n",
    "    return dat, Y\n",
    "\n",
    "create_data.count = 0\n",
    "\n",
    "x_train, y_train = create_data(n_train)\n",
    "x_calib, y_calib = create_data(n_val)\n",
    "x_test, y_test = create_data(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09ae5d-bc33-42eb-881f-0f9ec4056668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class trig_logistic:\n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression()#RandomForestClassifier(n_estimators=1000)\n",
    "        self.translate = np.pi*np.array([0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75])\n",
    "        self.freq = np.array([1, 2, 3, 4, 5, 6])\n",
    "        self.g1, self.g2 = np.meshgrid(self.translate, self.freq)\n",
    "    def create_features(self, x):\n",
    "        x_feats = np.zeros((x.shape[0], self.g1.size))\n",
    "        for i, el in enumerate(zip(self.g1.flatten(), self.g2.flatten())):\n",
    "            x_feats[:,i] = np.sin((x[:,0]+(el[0]*el[1]))/el[1])\n",
    "        return x_feats\n",
    "    def fit(self, x, y):\n",
    "        x_feats = self.create_features(x)\n",
    "        self.model.fit(x_feats, y)\n",
    "        return self\n",
    "    def predict_proba(self, x):\n",
    "        x_feats = self.create_features(x)\n",
    "        return self.model.predict_proba(x_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29b8c6-92f9-4d4b-95be-fa993d5bb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.vstack((np.arange(0, 20, 0.05), np.arange(0, 20, 0.05))).T\n",
    "x_feats = trig_logistic().create_features(x)\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,3),constrained_layout=True)\n",
    "for i in range(8, 16):\n",
    "    ax.plot(x[:,0] + x[:,1], x_feats[:,i], label = \"Feat {}\".format(i))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71797150-f17b-42bc-867e-22030f1d294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trig_logistic().fit(x_train, y_train)\n",
    "_, a_platt, b_platt = calibration.fit_platt_scaling_parameters(logit(model.predict_proba(x_calib)[:,1]), y_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160f51ff-8d6f-4f90-b82b-7017e62e124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_ons, a_platt_ons, b_platt_ons = calibration.online_platt_scaling_newton(logit(model.predict_proba(np.vstack((x_calib, x_test)))[:,1]), np.concatenate((y_calib, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196cfc90-378c-4108-99e2-0883e5cbe251",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a_platt_ons, label=\"a ONS\")\n",
    "plt.plot(b_platt_ons, label=\"b ONS\")\n",
    "plt.legend()\n",
    "plt.title(\"a_fixed = {:.2}, b_fixed = {:.2}\".format(a_platt[0], b_platt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72679e-16af-4bfb-8c86-a5868961e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "x_vals = (np.arange(-4, 30, 0.1)).reshape(-1,1)\n",
    "plt.hist(x_train[:,0], weights=0.003*np.ones(1000), alpha=0.2, label=\"Training data\")\n",
    "plt.hist(x_test[2000:2500,0], weights=0.007*np.ones(500), alpha=0.2, label=\"Test data from t = 2500 to t = 3000\")\n",
    "plt.hist(x_test[4000:,0], weights=0.007*np.ones(500), alpha=0.2, label=\"Test data from t = 4500 to t = 5000\")\n",
    "plt.plot([], [])\n",
    "plt.plot(x_vals[:,0], true_model.predict_proba(x_vals)[:,1], label = \"True model\", linestyle='--')\n",
    "plt.plot(x_vals[:,0], model.predict_proba(x_vals)[:,1], label = \"Original model\", linestyle='dotted')\n",
    "plt.plot(x_vals[:,0], sigmoid(a_platt*logit(model.predict_proba(x_vals)[:,1]) + b_platt), label = \"Fixed batch Platt scaling at t = 500\", linestyle='dashdot')\n",
    "plt.plot(x_vals[:,0], sigmoid(a_platt_ons[500]*logit(model.predict_proba(x_vals)[:,1]) + b_platt_ons[500]), label = \"Online Platt scaling at t = 2500\", linestyle='dashed')\n",
    "plt.plot(x_vals[:,0], sigmoid(a_platt_ons[2500]*logit(model.predict_proba(x_vals)[:,1]) + b_platt_ons[2500]), label = \"Online Platt scaling at t = 2500\", linestyle='dashed')\n",
    "plt.plot(x_vals[:,0], sigmoid(a_platt_ons[4500]*logit(model.predict_proba(x_vals)[:,1]) + b_platt_ons[4500]), label = \"Online Platt scaling at t = 4500\", linestyle=(0, (3, 2, 1, 2, 1, 2)))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xticks(fontsize=30); plt.yticks(fontsize=30);\n",
    "ax.set_ylim([0,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded07d0-e9a3-4789-8f28-ef101db376c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "x_vals = np.arange(-5, 30, 0.1).reshape((-1,1))\n",
    "\n",
    "true_probs = true_model.predict_proba(x_vals)[:,1]\n",
    "ax[0,0].plot([], []) \n",
    "ax[0,0].plot([], []) \n",
    "ax[0,0].plot([], [])\n",
    "ax[0,0].plot([], []) \n",
    "ax[0,0].plot(x_vals, true_probs, label = \"True probabilities at t = 0\", linestyle='solid') \n",
    "ax[0,0].plot([], [])\n",
    "ax[0,0].plot(x_vals, model.predict_proba(x_vals)[:,1], label = \"Fixed base model\", linestyle='dotted')#, color=line.get_color())\n",
    "utils.normalized_hist(x_train, ax[0,0])\n",
    "ax[0,0].set_title(r'$t = 1$ to $t = 1000$ (training)')\n",
    "\n",
    "t1 = 1500\n",
    "true_probs = true_model.predict_proba(x_vals)[:,1]\n",
    "ax[0,1].plot([], []) \n",
    "ax[0,1].plot([], []) \n",
    "ax[0,1].plot([], [])\n",
    "ax[0,1].plot([], [])\n",
    "ax[0,1].plot(x_vals, true_probs, label = \"True probabilities at t = 1500\", linestyle='solid')\n",
    "ax[0,1].plot([], []) \n",
    "ax[0,1].plot(x_vals, model.predict_proba(x_vals)[:,1], label = \"Fixed base model\", linestyle='dotted')#, color=line.get_color())\n",
    "ax[0,1].plot([], []) \n",
    "ax[0,1].plot(x_vals, sigmoid(a_platt_ons[t1-1000]*logit(model.predict_proba(x_vals)[:,1]) + b_platt_ons[t1-1000]), label = \"Online Platt scaling (OPS) at t = 1500\", linestyle='dashed')\n",
    "utils.normalized_hist(x_test[t1-1500:t1-1000], ax[0,1])\n",
    "ax[0,1].set_title(r'$t = 1501$ to $t = 2000$')\n",
    "\n",
    "t1 = 3500\n",
    "true_probs = true_model.predict_proba(x_vals)[:,1]\n",
    "ax[1,0].plot([], []) \n",
    "ax[1,0].plot([], []) \n",
    "ax[1,0].plot([], [])\n",
    "ax[1,0].plot([], [])\n",
    "ax[1,0].plot(x_vals, true_probs, label = \"True probabilities at t = 1500\", linestyle='solid')\n",
    "ax[1,0].plot([], []) \n",
    "ax[1,0].plot(x_vals, model.predict_proba(x_vals)[:,1], label = \"Fixed base model\", linestyle='dotted')#, color=line.get_color())\n",
    "ax[1,0].plot([], []) \n",
    "ax[1,0].plot(x_vals, sigmoid(a_platt_ons[t1-1000]*logit(model.predict_proba(x_vals)[:,1]) + b_platt_ons[t1-1000]), label = \"Online Platt scaling (OPS) at t = 1500\", linestyle='dashed')\n",
    "utils.normalized_hist(x_test[t1-1500:t1-1000], ax[1,0])\n",
    "ax[1,0].set_title(r'$t = 3501$ to $t = 4000$')\n",
    "\n",
    "t1 = 5500\n",
    "true_probs = true_model.predict_proba(x_vals)[:,1]\n",
    "ax[1,1].plot([], []) \n",
    "ax[1,1].plot([], []) \n",
    "ax[1,1].plot([], [])\n",
    "ax[1,1].plot([], [])\n",
    "ax[1,1].plot(x_vals, true_probs, label = \"True probabilities at t = 1500\", linestyle='solid')\n",
    "ax[1,1].plot([], []) \n",
    "ax[1,1].plot(x_vals, model.predict_proba(x_vals)[:,1], label = \"Fixed base model\", linestyle='dotted')#, color=line.get_color())\n",
    "ax[1,1].plot([], []) \n",
    "ax[1,1].plot(x_vals, sigmoid(a_platt_ons[t1-1000]*logit(model.predict_proba(x_vals)[:,1]) + b_platt_ons[t1-1000]), label = \"Online Platt scaling (OPS) at t = 5500\", linestyle='dashed')\n",
    "utils.normalized_hist(x_test[t1-1500:t1-1000], ax[1,1])\n",
    "ax[1,1].set_title(r'$t = 5501$ to $t = 6000$')\n",
    "\n",
    "fig.add_subplot(111, frameon=False)\n",
    "plt.grid(False)\n",
    "plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "plt.xlabel(r'Value of $x$', fontsize=22)\n",
    "plt.ylabel(r'True/predicted   Pr$(Y=1 \\mid X = x)$', fontsize=20)\n",
    "\n",
    "plt.savefig('results/covariate_shift_1d.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4dfa8-5d4d-40d8-9380-275f0fae9146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vals(y_pred_probs, true_probs):\n",
    "    y_pred_classes = (y_pred_probs>=0.5).astype('int')\n",
    "    ece = 0\n",
    "    bin_edges = np.sort(np.unique(y_pred_probs))\n",
    "    bin_assignment = utils.bin_points(y_pred_probs, bin_edges)\n",
    "    tot_elem = 0\n",
    "    for i, bin_edges in enumerate(bin_edges):\n",
    "        bin_idx = (bin_assignment == i)\n",
    "        assert(sum(bin_idx) > 0), \"This assert should pass by construction of the code\"\n",
    "        n_elem = sum(bin_idx)\n",
    "        tot_elem += n_elem\n",
    "        pi_pred = y_pred_probs[bin_idx].mean()\n",
    "        pi_true = true_probs[bin_idx].mean()\n",
    "        ece += n_elem*np.abs(pi_pred-pi_true)\n",
    "    assert(tot_elem == y_pred_probs.size)\n",
    "    ece /= y_pred_probs.size\n",
    "    acc = np.sum(np.multiply(true_probs, y_pred_classes) + np.multiply(1-true_probs,1-y_pred_classes))/y_pred_probs.size    \n",
    "\n",
    "    print(\"{:.2f}\\\\% & {:.2}\".format(100*acc, ece))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e823325-3342-4528-aa86-05b9e0e55096",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = model.predict_proba(x_train)[:,1]\n",
    "true_probs = true_model.predict_proba(x_train)[:,1]\n",
    "print_vals(y_pred_probs, true_probs)\n",
    "for base_val in [0, 2000, 4000]:\n",
    "    y_pred_probs = model.predict_proba(x_test)[base_val:(base_val+500),1]\n",
    "    true_probs = true_model.predict_proba(x_test)[base_val:(base_val+500),1]\n",
    "    print_vals(y_pred_probs, true_probs)\n",
    "    y_pred_probs = sigmoid(np.multiply(a_platt_ons[(base_val + 500):(base_val + 1000)], \n",
    "                                       logit(model.predict_proba(x_test)[base_val:(base_val+500),1])) +\n",
    "                           b_platt_ons[(base_val + 500):(base_val + 1000)])\n",
    "    print_vals(y_pred_probs, true_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
